
# Utilizing Pointnet for Classification and Segmentation of Grapes

## Requirements

The Pointnet and Pointnet++ Models are written in pure PyTorch. You can create a conda environment from the provided requirements.yml file:

```bash
conda env create -n Pointnet -f requirements.yml
```

## Datastructure

After downloading the original pointcloud data you can preprocess and create the folderstructure expected by the training skipts by running the following command. This can take up to ~2.5 hours.

```bash
python utils/data.py --f PATH/TO/FOLDER
```

Where PATH/TO/FOLDER is the path to the download folder which should have the following structure:

```bash
DownloadFolder
├── BBCH87_89
│   ├── CalardisBlanc
│   ├── Dornfelder
│   ├── PinotNoir
│   ├── Riesling
│   │   ├── *.xyzrgb
├── Labeling_GT
│   ├── BBCH87_89
│   │   ├── *.xyzrgb
├── Skeletons
│   ├── CalardisBlanc
│   ├── Dornfelder
│   ├── PinotNoir
│   │   ├── *.xyzrgb
```

## Training

For training a model we provide both python skipts as well as jupiter notebooks to train on google colab for almost all tasks. To train a model for a specific task just run the corresponding command.

```bash
python train_cls.py                 // classification
python train_cls_compactness.py     // classification
python train_seg.py                 // segmentation
python train_seg_hierarchical.py    // hierarchical segmentation
```

Each skipt will generate a folder that holds a config.json file, the model parameters for encoder and decoder as well as a board.txt file which presents some statistics.

## Visualize Resulting Segmentations

To visualize the prediction of a segmentation model make use of the visualize.py file by running:

```bash
python visualize.py --model PATH/TO/MODEL --f PATH/TO/POINTCLOUD
```

Here PATH/TO/MODEL names a path to a folder that holds the config.json file as well as the model parameters and PATH/TO/POINTCLOUD refers to a pointcloud in .feats file format as generated by `utils/data.py`.
