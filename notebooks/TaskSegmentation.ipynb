{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pointnet4BerriesSegmentation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ZPgsL_hkRIF6","colab_type":"text"},"source":["## Clone Github Repository"]},{"cell_type":"code","metadata":{"id":"z19q9N0-RNOo","colab_type":"code","outputId":"f90ae55e-0748-462f-8457-ff7e4356269c","executionInfo":{"status":"ok","timestamp":1585248615815,"user_tz":-60,"elapsed":6246,"user":{"displayName":"Niclas Doll","photoUrl":"","userId":"03509535029183763642"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# clone repository\n","!git clone https://github.com/ndoll1998/Pointnet4Berries.git P4B"],"execution_count":1,"outputs":[{"output_type":"stream","text":["fatal: destination path 'P4B' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P7Dp_Y54RiNb","colab_type":"text"},"source":["## Imports"]},{"cell_type":"code","metadata":{"id":"Y2GTB8OxRk1H","colab_type":"code","outputId":"ba728b79-01a1-445c-d6b1-071dfcac3ba6","executionInfo":{"status":"ok","timestamp":1585248616255,"user_tz":-60,"elapsed":6668,"user":{"displayName":"Niclas Doll","photoUrl":"","userId":"03509535029183763642"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# imports\n","import sys\n","import numpy as np\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","# import model and utils\n","from P4B.Pointnet.models import Model_SEG\n","from P4B.utils.data import build_data_seg, seg_file_features\n","from P4B.utils.utils import compute_fscores\n","from P4B.utils.augmentation import Augmenter, augment_rotate_pointcloud\n","from P4B.utils.torchBoard import TorchBoard, ConfusionMatrix\n","# import others\n","import os\n","import json\n","from time import time\n","from tqdm import tqdm\n","from random import sample\n","from collections import OrderedDict\n","# import google colab\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"h8zmuAskV259","colab_type":"text"},"source":["## Set Up"]},{"cell_type":"code","metadata":{"id":"6BLnb3KGV7Ma","colab_type":"code","colab":{}},"source":["# cude device to use\n","device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","# class bins\n","class_bins = OrderedDict({\n","    'twig': ['twig'],\n","    'subtwig': ['subtwig', 'berry'],\n","    'rachis': ['rachis'],\n","    'peduncle': ['peduncle'],\n","    'hook': ['hook'],\n","}); K = len(class_bins)\n","# augmentations\n","augmentations = [\n","    Augmenter(augment_rotate_pointcloud, feats=seg_file_features, apply_count=20, rot_axis='xyz')\n","]\n","# used features\n","features = ['x', 'y', 'z', 'r', 'g', 'b'] #, 'length-xy', 'curvature']\n","feature_dim = len(features) - 3\n","# number of points and samples\n","n_points = 70_000\n","n_samples = 5\n","# number of poinclouds per class for testing\n","n_test_pcs = 1\n","# initial checkpoint\n","encoder_init_checkpoint = None\n","segmentater_init_checkpoint = None\n","# training parameters\n","epochs = 500\n","batch_size = 4\n","# optimizer parameters\n","lr = 5e-4\n","weight_decay = 1e-2\n","# path to files\n","fpath = \"drive/My Drive/P4B/data/Segmentation\"\n","# save path\n","save_path = \"drive/My Drive/P4B/results/segmentation_v1\"\n","os.makedirs(save_path, exist_ok=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CRzkJhT3WxZH","colab_type":"text"},"source":["## Load Data"]},{"cell_type":"code","metadata":{"id":"JnoLq8ZBW0jG","colab_type":"code","outputId":"0da12088-16ae-420a-e177-dd290c9d25a4","executionInfo":{"status":"ok","timestamp":1585248645205,"user_tz":-60,"elapsed":35574,"user":{"displayName":"Niclas Doll","photoUrl":"","userId":"03509535029183763642"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pointclouds = {}\n","# open files\n","for fname in tqdm(os.listdir(fpath)):\n","    if 'CB_' in fname:\n","        continue\n","    # get name of pointcloud\n","    class_name, name = fname.replace('.xyzrgbc', '').split('_')[:2]\n","    # check for entry in pointclouds\n","    if class_name not in pointclouds:\n","        pointclouds[class_name] = {}\n","    if name not in pointclouds[class_name]:\n","        pointclouds[class_name][name] = []\n","    # create full path to file\n","    full_path = os.path.join(fpath, fname)\n","    # read pointcloud\n","    pointclouds[class_name][name].append(np.loadtxt(full_path, dtype=np.float32))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["100%|██████████| 14/14 [00:28<00:00,  2.06s/it]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"6_VEl565fytI","colab_type":"text"},"source":["## Generate Training and Testing Data"]},{"cell_type":"code","metadata":{"id":"OlAb6Phmf1h7","colab_type":"code","outputId":"a7a2a886-a6dd-4533-f614-a26fad801982","executionInfo":{"status":"ok","timestamp":1585249101930,"user_tz":-60,"elapsed":492034,"user":{"displayName":"Niclas Doll","photoUrl":"","userId":"03509535029183763642"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# separate pointclouds into training and testing samples\n","train_pointclouds, test_pointclouds = {}, {}\n","for class_name, pcs in pointclouds.items():\n","    # get random subset to train from\n","    train_pc_names = sample(pcs.keys(), len(pcs) - n_test_pcs)\n","    test_pc_names = set(pcs.keys()) - set(train_pc_names)\n","    # add to dicts\n","    train_pointclouds[class_name] = sum([pcs[n] for n in train_pc_names], [])\n","    test_pointclouds[class_name] = sum([pcs[n] for n in test_pc_names], [])\n","# create training and testing datasets\n","train_data = TensorDataset(*build_data_seg(train_pointclouds, n_points, n_samples, class_bins, features=features, augmentations=augmentations))\n","test_data = TensorDataset(*build_data_seg(test_pointclouds, n_points, n_samples, class_bins, features=features, augmentations=augmentations))\n","# create training and testing dataloaders\n","train_dataloader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n","test_dataloader = DataLoader(test_data, shuffle=False, batch_size=1)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["pc: 100%|██████████| 168/168 [06:10<00:00,  2.20s/it]\n","pc: 100%|██████████| 42/42 [01:07<00:00,  1.60s/it]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"4ehBK372W8Sg","colab_type":"text"},"source":["## Create Model and Optimizer"]},{"cell_type":"code","metadata":{"id":"Dm0bU518XAE1","colab_type":"code","colab":{}},"source":["# create model\n","model = Model_SEG(K=K, feat_dim=feature_dim)\n","model.load_encoder(encoder_init_checkpoint)\n","model.load_segmentater(segmentater_init_checkpoint)\n","model.to(device)\n","# create optimizer\n","optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jD5-H-2pXDg9","colab_type":"text"},"source":["## Save Confugurations"]},{"cell_type":"code","metadata":{"id":"wyLdBW61XHXm","colab_type":"code","colab":{}},"source":["# build config\n","config = {\n","    \"task\": \"segmentation\",\n","    \"augmentation\": [augment.dict() for augment in augmentations],\n","    \"data\": {\n","        \"classes\": class_bins,\n","        \"features\": features,\n","        \"feature_dim\": feature_dim,\n","        \"n_points\": n_points,\n","        \"n_samples\": n_samples, \n","        \"n_test_pointclouds\": n_test_pcs,\n","        \"n_train_samples\": len(train_data),\n","        \"n_train_points\": dict(zip(class_bins.keys(), map(int, np.bincount(train_data[:][-1].flatten().numpy())))),\n","        \"n_test_samples\": len(test_data),\n","        \"n_test_points\": dict(zip(class_bins.keys(), map(int, np.bincount(test_data[:][-1].flatten().numpy())))),\n","    },\n","    \"training\": {\n","        \"epochs\": epochs,\n","        \"batch_size\": batch_size,\n","    },\n","    \"optimizer\": {\n","        \"learning_rate\": lr,\n","        \"weight_decay\": weight_decay\n","    }\n","}\n","# save to file\n","with open(os.path.join(save_path, \"config.json\"), 'w+') as f:\n","    json.dump(config, f, indent=2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LXFnPysXXQk9","colab_type":"text"},"source":["## Train and evaluate Model"]},{"cell_type":"code","metadata":{"id":"7PdTQu-UXVfE","colab_type":"code","outputId":"a1cb2d60-f12b-4059-e896-4bb294a2fba5","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# track losses and f-scores\n","tb = TorchBoard(\"Train_Loss\", \"Test_Loss\", *class_bins.keys())\n","tb.add_stat(ConfusionMatrix(class_bins.keys(), name=\"Confusion\", normalize=True))\n","# compute loss weights of each class by the number of points associated\n","weight = torch.from_numpy(1 / np.power(np.bincount(train_data[:][-1].flatten().numpy()), 1))\n","weight = (weight / weight.sum()).float().to(device)\n","\n","best_fscore, start = -1, time()\n","for epoch in range(epochs):\n","\n","    # train model\n","    model.train()\n","    # reset for epoch\n","    start_epoch = time()\n","    running_loss = 0\n","\n","    # train loop\n","    for i, (x, y_hat) in enumerate(train_dataloader):\n","        optim.zero_grad()\n","\n","        # pass through model\n","        y = model.forward(x.to(device))\n","        # compute error\n","        loss = model.loss(y, y_hat.to(device), weight=weight)\n","        running_loss += loss.item()\n","        # update model parameters\n","        loss.backward()\n","        optim.step()\n","        # log\n","        print(\"\\rEpoch {0}/{1}\\t- Batch {2}/{3}\\t- Average Loss {4:.02f}\\t - Time {5:.04f}s\"\n","            .format(epoch+1, epochs, i+1, len(train_dataloader), running_loss/(i+1), time() - start), end='', flush=True)\n","\n","    # add to statistic\n","    tb.Train_Loss += running_loss / len(train_dataloader)\n","\n","    # eval model\n","    model.eval()\n","    # initialize confusion matrix\n","    confusion_matrix = np.zeros((K, K))\n","    running_loss = 0\n","\n","    for x, y_hat in test_dataloader:\n","        # pass through model and compute error\n","        y = model.forward(x.to(device))\n","        running_loss += model.loss(y, y_hat.to(device), weight=weight).item()\n","        # update confusion matrix\n","        for actual, pred in zip(y_hat.flatten().cpu().numpy(), torch.argmax(y.reshape(-1, K), dim=-1).cpu().numpy()):\n","            confusion_matrix[actual, pred] += 1\n","\n","    # update board\n","    tb.Confusion += confusion_matrix\n","    tb.Test_Loss += running_loss / len(test_dataloader)\n","    # compute f-scores from confusion matrix\n","    f_scores = compute_fscores(confusion_matrix)\n","    for c, f in zip(class_bins.keys(), f_scores):\n","        tb[c] += f\n","    # save board\n","    fig = tb.create_fig([[[\"Train_Loss\", \"Test_Loss\"]], [class_bins.keys()], [[\"Confusion\"]]], figsize=(8, 11))\n","    fig.savefig(os.path.join(save_path, \"board.pdf\"), format=\"pdf\")\n","    # save model and best board if fscores improved\n","    if sum(f_scores) > best_fscore:\n","        fig.savefig(os.path.join(save_path, \"best_board.pdf\"), format=\"pdf\")\n","        model.save(save_path)\n","        best_fscore = sum(f_scores)\n","    # end epoch\n","    print()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/500\t- Batch 210/210\t- Average Loss 1.63\t - Time 28.4052s\n","Epoch 2/500\t- Batch 210/210\t- Average Loss 1.46\t - Time 75.6131s\n","Epoch 3/500\t- Batch 210/210\t- Average Loss 1.35\t - Time 123.1724s\n","Epoch 4/500\t- Batch 210/210\t- Average Loss 1.27\t - Time 170.7319s\n","Epoch 5/500\t- Batch 210/210\t- Average Loss 1.17\t - Time 218.7655s\n","Epoch 6/500\t- Batch 210/210\t- Average Loss 1.10\t - Time 266.1420s\n","Epoch 7/500\t- Batch 210/210\t- Average Loss 1.06\t - Time 314.0789s\n","Epoch 8/500\t- Batch 210/210\t- Average Loss 1.03\t - Time 362.5384s\n","Epoch 9/500\t- Batch 210/210\t- Average Loss 1.01\t - Time 410.2122s\n","Epoch 10/500\t- Batch 210/210\t- Average Loss 1.00\t - Time 457.5492s\n","Epoch 11/500\t- Batch 210/210\t- Average Loss 0.99\t - Time 505.3219s\n","Epoch 12/500\t- Batch 210/210\t- Average Loss 0.97\t - Time 553.0744s\n","Epoch 13/500\t- Batch 210/210\t- Average Loss 0.96\t - Time 600.9064s\n","Epoch 14/500\t- Batch 210/210\t- Average Loss 0.96\t - Time 649.0862s\n","Epoch 15/500\t- Batch 210/210\t- Average Loss 0.94\t - Time 696.6781s\n","Epoch 16/500\t- Batch 210/210\t- Average Loss 0.94\t - Time 743.9545s\n","Epoch 17/500\t- Batch 210/210\t- Average Loss 0.93\t - Time 792.1843s\n","Epoch 18/500\t- Batch 210/210\t- Average Loss 0.92\t - Time 840.0679s\n","Epoch 19/500\t- Batch 210/210\t- Average Loss 0.91\t - Time 887.9322s\n","Epoch 20/500\t- Batch 210/210\t- Average Loss 0.91\t - Time 935.4147s\n","Epoch 21/500\t- Batch 210/210\t- Average Loss 0.89\t - Time 983.1016s\n","Epoch 22/500\t- Batch 210/210\t- Average Loss 0.88\t - Time 1030.8917s\n","Epoch 23/500\t- Batch 210/210\t- Average Loss 0.88\t - Time 1079.9607s\n","Epoch 24/500\t- Batch 210/210\t- Average Loss 0.87\t - Time 1128.4656s\n","Epoch 25/500\t- Batch 210/210\t- Average Loss 0.86\t - Time 1177.2559s\n","Epoch 26/500\t- Batch 210/210\t- Average Loss 0.86\t - Time 1226.0670s\n","Epoch 27/500\t- Batch 210/210\t- Average Loss 0.85\t - Time 1274.0984s\n","Epoch 28/500\t- Batch 210/210\t- Average Loss 0.85\t - Time 1322.1792s\n","Epoch 29/500\t- Batch 210/210\t- Average Loss 0.83\t - Time 1370.1527s\n","Epoch 30/500\t- Batch 210/210\t- Average Loss 0.84\t - Time 1417.8329s\n","Epoch 31/500\t- Batch 210/210\t- Average Loss 0.84\t - Time 1465.5231s\n","Epoch 32/500\t- Batch 210/210\t- Average Loss 0.83\t - Time 1513.6394s\n","Epoch 33/500\t- Batch 210/210\t- Average Loss 0.82\t - Time 1561.6109s\n","Epoch 34/500\t- Batch 210/210\t- Average Loss 0.82\t - Time 1609.2433s\n","Epoch 35/500\t- Batch 210/210\t- Average Loss 0.83\t - Time 1656.8381s\n","Epoch 36/500\t- Batch 210/210\t- Average Loss 0.82\t - Time 1704.6314s\n","Epoch 37/500\t- Batch 210/210\t- Average Loss 0.83\t - Time 1752.2167s\n","Epoch 38/500\t- Batch 210/210\t- Average Loss 0.83\t - Time 1799.9422s\n","Epoch 39/500\t- Batch 210/210\t- Average Loss 0.81\t - Time 1847.4110s\n","Epoch 40/500\t- Batch 210/210\t- Average Loss 0.80\t - Time 1895.6457s\n","Epoch 41/500\t- Batch 210/210\t- Average Loss 0.81\t - Time 1943.4800s\n","Epoch 42/500\t- Batch 210/210\t- Average Loss 0.80\t - Time 1991.2779s\n","Epoch 43/500\t- Batch 210/210\t- Average Loss 0.80\t - Time 2039.2674s\n","Epoch 44/500\t- Batch 210/210\t- Average Loss 0.80\t - Time 2086.9920s\n","Epoch 45/500\t- Batch 210/210\t- Average Loss 0.81\t - Time 2134.4800s\n","Epoch 46/500\t- Batch 210/210\t- Average Loss 0.80\t - Time 2181.9244s\n","Epoch 47/500\t- Batch 210/210\t- Average Loss 0.80\t - Time 2229.8520s\n","Epoch 48/500\t- Batch 210/210\t- Average Loss 0.79\t - Time 2277.5420s\n","Epoch 49/500\t- Batch 210/210\t- Average Loss 0.80\t - Time 2325.2252s\n","Epoch 50/500\t- Batch 210/210\t- Average Loss 0.80\t - Time 2373.0651s\n","Epoch 51/500\t- Batch 210/210\t- Average Loss 0.80\t - Time 2420.6873s\n","Epoch 52/500\t- Batch 210/210\t- Average Loss 0.79\t - Time 2468.6049s\n","Epoch 53/500\t- Batch 210/210\t- Average Loss 0.78\t - Time 2516.6303s\n","Epoch 54/500\t- Batch 210/210\t- Average Loss 0.78\t - Time 2564.6384s\n","Epoch 55/500\t- Batch 210/210\t- Average Loss 0.79\t - Time 2612.4511s\n","Epoch 56/500\t- Batch 210/210\t- Average Loss 0.79\t - Time 2659.9156s\n","Epoch 57/500\t- Batch 210/210\t- Average Loss 0.79\t - Time 2706.6475s\n","Epoch 58/500\t- Batch 210/210\t- Average Loss 0.80\t - Time 2754.2883s\n","Epoch 59/500\t- Batch 210/210\t- Average Loss 0.79\t - Time 2801.4380s\n","Epoch 60/500\t- Batch 210/210\t- Average Loss 0.78\t - Time 2848.0265s\n","Epoch 61/500\t- Batch 210/210\t- Average Loss 0.77\t - Time 2895.4619s\n","Epoch 62/500\t- Batch 210/210\t- Average Loss 0.78\t - Time 2942.6798s\n","Epoch 63/500\t- Batch 210/210\t- Average Loss 0.77\t - Time 2989.9786s\n","Epoch 64/500\t- Batch 210/210\t- Average Loss 0.77\t - Time 3037.4201s\n","Epoch 65/500\t- Batch 210/210\t- Average Loss 0.78\t - Time 3084.6231s\n","Epoch 66/500\t- Batch 210/210\t- Average Loss 0.78\t - Time 3132.3633s\n","Epoch 67/500\t- Batch 210/210\t- Average Loss 0.78\t - Time 3179.8930s\n","Epoch 68/500\t- Batch 210/210\t- Average Loss 0.78\t - Time 3226.8815s\n","Epoch 69/500\t- Batch 210/210\t- Average Loss 0.77\t - Time 3273.9360s\n","Epoch 70/500\t- Batch 210/210\t- Average Loss 0.77\t - Time 3320.6515s\n","Epoch 71/500\t- Batch 210/210\t- Average Loss 0.78\t - Time 3367.8782s\n","Epoch 72/500\t- Batch 210/210\t- Average Loss 0.77\t - Time 3415.0501s\n","Epoch 73/500\t- Batch 210/210\t- Average Loss 0.78\t - Time 3461.7787s\n","Epoch 74/500\t- Batch 210/210\t- Average Loss 0.77\t - Time 3508.5006s\n","Epoch 75/500\t- Batch 210/210\t- Average Loss 0.77\t - Time 3555.1772s\n","Epoch 76/500\t- Batch 210/210\t- Average Loss 0.77\t - Time 3601.7099s\n","Epoch 77/500\t- Batch 210/210\t- Average Loss 0.77\t - Time 3648.6017s\n","Epoch 78/500\t- Batch 210/210\t- Average Loss 0.77\t - Time 3695.4290s\n","Epoch 79/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 3741.9837s\n","Epoch 80/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 3788.7791s\n","Epoch 81/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 3835.4166s\n","Epoch 82/500\t- Batch 210/210\t- Average Loss 0.77\t - Time 3881.7794s\n","Epoch 83/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 3927.9543s\n","Epoch 84/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 3974.2661s\n","Epoch 85/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 4020.8053s\n","Epoch 86/500\t- Batch 210/210\t- Average Loss 0.78\t - Time 4067.5454s\n","Epoch 87/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 4114.2265s\n","Epoch 88/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 4160.2953s\n","Epoch 89/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 4206.8348s\n","Epoch 90/500\t- Batch 210/210\t- Average Loss 0.77\t - Time 4253.4543s\n","Epoch 91/500\t- Batch 210/210\t- Average Loss 0.77\t - Time 4300.2997s\n","Epoch 92/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 4347.3110s\n","Epoch 93/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 4395.1628s\n","Epoch 94/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 4442.1530s\n","Epoch 95/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 4489.2007s\n","Epoch 96/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 4536.0475s\n","Epoch 97/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 4583.6247s\n","Epoch 98/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 4631.4130s\n","Epoch 99/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 4678.8025s\n","Epoch 100/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 4726.1356s\n","Epoch 101/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 4773.4795s\n","Epoch 102/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 4820.5944s\n","Epoch 103/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 4867.7481s\n","Epoch 104/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 4914.4675s\n","Epoch 105/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 4961.0115s\n","Epoch 106/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 5008.1340s\n","Epoch 107/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 5054.3669s\n","Epoch 108/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 5100.7445s\n","Epoch 109/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 5146.6480s\n","Epoch 110/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 5192.6836s\n","Epoch 111/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 5238.7639s\n","Epoch 112/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 5285.3390s\n","Epoch 113/500\t- Batch 210/210\t- Average Loss 0.77\t - Time 5331.5285s\n","Epoch 114/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 5377.9376s\n","Epoch 115/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 5424.2066s\n","Epoch 116/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 5470.3946s\n","Epoch 117/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 5517.0191s\n","Epoch 118/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 5563.7934s\n","Epoch 119/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 5611.9444s\n","Epoch 120/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 5659.2523s\n","Epoch 121/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 5706.9027s\n","Epoch 122/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 5754.7755s\n","Epoch 123/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 5802.3870s\n","Epoch 124/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 5850.1727s\n","Epoch 125/500\t- Batch 210/210\t- Average Loss 0.77\t - Time 5897.9749s\n","Epoch 126/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 5946.3177s\n","Epoch 127/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 5994.3689s\n","Epoch 128/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 6042.8306s\n","Epoch 129/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 6090.7369s\n","Epoch 130/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 6138.6307s\n","Epoch 131/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 6186.8686s\n","Epoch 132/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 6234.9622s\n","Epoch 133/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 6282.9087s\n","Epoch 134/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 6330.6892s\n","Epoch 135/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 6377.9729s\n","Epoch 136/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 6425.2088s\n","Epoch 137/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 6472.4943s\n","Epoch 138/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 6520.0333s\n","Epoch 139/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 6567.7632s\n","Epoch 140/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 6615.0893s\n","Epoch 141/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 6662.4601s\n","Epoch 142/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 6709.9315s\n","Epoch 143/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 6756.9606s\n","Epoch 144/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 6804.3276s\n","Epoch 145/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 6851.8610s\n","Epoch 146/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 6899.5195s\n","Epoch 147/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 6947.3859s\n","Epoch 148/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 6995.2827s\n","Epoch 149/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 7043.2538s\n","Epoch 150/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 7091.2828s\n","Epoch 151/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 7138.9340s\n","Epoch 152/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 7186.9110s\n","Epoch 153/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 7233.8707s\n","Epoch 154/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 7280.8559s\n","Epoch 155/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 7327.6346s\n","Epoch 156/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 7374.3677s\n","Epoch 157/500\t- Batch 210/210\t- Average Loss 0.73\t - Time 7421.3193s\n","Epoch 158/500\t- Batch 210/210\t- Average Loss 0.76\t - Time 7468.1110s\n","Epoch 159/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 7514.8552s\n","Epoch 160/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 7561.7037s\n","Epoch 161/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 7608.2015s\n","Epoch 162/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 7655.0505s\n","Epoch 163/500\t- Batch 210/210\t- Average Loss 0.73\t - Time 7701.5847s\n","Epoch 164/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 7748.3060s\n","Epoch 165/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 7794.8687s\n","Epoch 166/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 7841.0734s\n","Epoch 167/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 7887.4147s\n","Epoch 168/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 7933.7692s\n","Epoch 169/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 7980.1674s\n","Epoch 170/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 8026.7562s\n","Epoch 171/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 8073.2374s\n","Epoch 172/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 8119.8972s\n","Epoch 173/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 8166.1880s\n","Epoch 174/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 8212.6365s\n","Epoch 175/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 8259.1452s\n","Epoch 176/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 8305.8784s\n","Epoch 177/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 8352.3907s\n","Epoch 178/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 8398.9071s\n","Epoch 179/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 8445.5377s\n","Epoch 180/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 8492.0929s\n","Epoch 181/500\t- Batch 210/210\t- Average Loss 0.73\t - Time 8538.8732s\n","Epoch 182/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 8585.9005s\n","Epoch 183/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 8632.4982s\n","Epoch 184/500\t- Batch 210/210\t- Average Loss 0.73\t - Time 8679.0884s\n","Epoch 185/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 8725.7299s\n","Epoch 186/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 8772.2516s\n","Epoch 187/500\t- Batch 210/210\t- Average Loss 0.73\t - Time 8818.8626s\n","Epoch 188/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 8865.4668s\n","Epoch 189/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 8912.2550s\n","Epoch 190/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 8959.0196s\n","Epoch 191/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 9005.5752s\n","Epoch 192/500\t- Batch 210/210\t- Average Loss 0.73\t - Time 9052.4009s\n","Epoch 193/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 9100.1971s\n","Epoch 194/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 9147.0766s\n","Epoch 195/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 9193.6540s\n","Epoch 196/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 9240.6080s\n","Epoch 197/500\t- Batch 210/210\t- Average Loss 0.73\t - Time 9286.8954s\n","Epoch 198/500\t- Batch 210/210\t- Average Loss 0.73\t - Time 9333.5690s\n","Epoch 199/500\t- Batch 210/210\t- Average Loss 0.72\t - Time 9379.9306s\n","Epoch 200/500\t- Batch 210/210\t- Average Loss 0.73\t - Time 9426.5063s\n","Epoch 201/500\t- Batch 210/210\t- Average Loss 0.75\t - Time 9472.6665s\n","Epoch 202/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 9519.1671s\n","Epoch 203/500\t- Batch 210/210\t- Average Loss 0.73\t - Time 9565.5975s\n","Epoch 204/500\t- Batch 210/210\t- Average Loss 0.73\t - Time 9612.2228s\n","Epoch 205/500\t- Batch 210/210\t- Average Loss 0.73\t - Time 9659.0126s\n","Epoch 206/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 9705.6115s\n","Epoch 207/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 9752.3699s\n","Epoch 208/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 9799.0418s\n","Epoch 209/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 9845.6221s\n","Epoch 210/500\t- Batch 210/210\t- Average Loss 0.73\t - Time 9892.3596s\n","Epoch 211/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 9939.0535s\n","Epoch 212/500\t- Batch 210/210\t- Average Loss 0.74\t - Time 9985.7807s\n","Epoch 213/500\t- Batch 210/210\t- Average Loss 0.73\t - Time 10032.5025s"],"name":"stdout"}]}]}